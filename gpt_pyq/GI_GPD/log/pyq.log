MPI version is unknown - bad things may happen
AcceleratorCudaInit[0]: ========================
AcceleratorCudaInit[0]: Device Number    : 0
AcceleratorCudaInit[0]: ========================
AcceleratorCudaInit[0]: Device identifier: NVIDIA GeForce RTX 3060
AcceleratorCudaInit[0]:   totalGlobalMem: 12626493440 
AcceleratorCudaInit[0]:   managedMemory: 1 
AcceleratorCudaInit[0]:   isMultiGpuBoard: 0 
AcceleratorCudaInit[0]:   warpSize: 32 
AcceleratorCudaInit[0]:   pciBusID: 7 
AcceleratorCudaInit[0]:   pciDeviceID: 0 
AcceleratorCudaInit[0]: maxGridSize (2147483647,65535,65535)
AcceleratorCudaInit: using default device 
AcceleratorCudaInit: assume user either uses
AcceleratorCudaInit: a) IBM jsrun, or 
AcceleratorCudaInit: b) invokes through a wrapping script to set CUDA_VISIBLE_DEVICES, UCX_NET_DEVICES, and numa binding 
AcceleratorCudaInit: Configure options --enable-setdevice=no 
local rank 0 device 0 bus id: 0000:07:00.0
AcceleratorCudaInit: ================================================
SharedMemoryMpi:  World communicator of size 1
SharedMemoryMpi:  Node  communicator of size 1
0SharedMemoryMpi:  SharedMemoryMPI.cc acceleratorAllocDevice 1073741824bytes at 0x7d6c0e000000 - 7d6c4dffffff for comms buffers 
Setting up IPC

__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
__|_ |  |  |  |  |  |  |  |  |  |  |  | _|__
__|_                                    _|__
__|_   GGGG    RRRR    III    DDDD      _|__
__|_  G        R   R    I     D   D     _|__
__|_  G        R   R    I     D    D    _|__
__|_  G  GG    RRRR     I     D    D    _|__
__|_  G   G    R  R     I     D   D     _|__
__|_   GGGG    R   R   III    DDDD      _|__
__|_                                    _|__
__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
  |  |  |  |  |  |  |  |  |  |  |  |  |  |  


Copyright (C) 2015 Peter Boyle, Azusa Yamaguchi, Guido Cossu, Antonin Portelli and other authors

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
Current Grid git commit hash=46c717e873bb91677e8961a6fc5bfc58bc2171a5: (HEAD -> gpt_proton, origin/gpt_proton) clean

Grid : Message : ================================================ 
Grid : Message : MPI is initialised and logging filters activated 
Grid : Message : ================================================ 
Grid : Message : This rank is running on host Moonway
Grid : Message : Requested 1073741824 byte stencil comms buffers 
Grid : Message : MemoryManager Cache 10101194752 bytes 
Grid : Message : MemoryManager::Init() setting up
Grid : Message : MemoryManager::Init() cache pool for recent host   allocations: SMALL 8 LARGE 2 HUGE 0
Grid : Message : MemoryManager::Init() cache pool for recent device allocations: SMALL 16 LARGE 8 Huge 0
Grid : Message : MemoryManager::Init() cache pool for recent shared allocations: SMALL 16 LARGE 8 Huge 0
Grid : Message : MemoryManager::Init() Non unified: Caching accelerator data in dedicated memory
Grid : Message : MemoryManager::Init() Using cudaMalloc

=============================================
              Initialized GPT                
     Copyright (C) 2020 Christoph Lehner     
=============================================
GPT :       0.917247 s : --lat_tag l64c64a076
GPT :       0.917280 s : --sm_tag 1HYP_GSRC_W90_k3_T5
GPT :       0.917287 s : --config_num 0
PyQUDA INFO: Using the grid size (1, 1, 1, 1)
PyQUDA INFO: Using CUDA backend cupy
PyQUDA INFO: Using QUDA_RESOURCE_PATH=.cache
Disabling GPU-Direct RDMA access
Enabling peer-to-peer copy engine and direct load/store access
QUDA 1.1.0 (git 1.1.0-e23cd7e4f-sm_86)
CUDA Driver version = 12020
CUDA Runtime version = 12020
Graphic driver version = 535.261.03
Found device 0: NVIDIA GeForce RTX 3060
Using device 0: NVIDIA GeForce RTX 3060
Initializing monitoring on device 0: NVIDIA GeForce RTX 3060
WARNING: Data reordering done on GPU (set with QUDA_REORDER_LOCATION=GPU/CPU)
WARNING: The path ".cache" specified by QUDA_RESOURCE_PATH does not exist or is not a directory.
WARNING: Caching of tuned parameters will be disabled
WARNING: Cache file not found.  All kernels will be re-tuned (if tuning is enabled).
WARNING: Using device memory pool allocator
WARNING: Using pinned memory pool allocator
cublasCreated successfully
GPT :       0.947393 s : NERSC file format; reading ../../conf/S8T32_cg/gauge/wilson_b6.cg.1e-08.0
GPT :       0.947408 s :    BEGIN_HEADER
GPT :       0.947414 s : 	HDR_VERSION = 1.0
GPT :       0.947420 s : 	DATATYPE = 4D_SU3_GAUGE_3x3
GPT :       0.947424 s : 	STORAGE_FORMAT =
GPT :       0.947428 s : 	DIMENSION_1 = 8
GPT :       0.947433 s : 	DIMENSION_2 = 8
GPT :       0.947437 s : 	DIMENSION_3 = 8
GPT :       0.947440 s : 	DIMENSION_4 = 32
GPT :       0.947444 s : 	LINK_TRACE = 0.6662761893
GPT :       0.947448 s : 	PLAQUETTE  = 0.595124939
GPT :       0.947453 s : 	BOUNDARY_1 = PERIODIC
GPT :       0.947456 s : 	BOUNDARY_2 = PERIODIC
GPT :       0.947460 s : 	BOUNDARY_3 = PERIODIC
GPT :       0.947464 s : 	BOUNDARY_4 = PERIODIC
GPT :       0.947467 s : 	CHECKSUM =   d62a45d9
GPT :       0.947471 s : 	SCIDAC_CHECKSUMA =          0
GPT :       0.947475 s : 	SCIDAC_CHECKSUMB =          0
GPT :       0.947479 s : 	ENSEMBLE_ID = gpt
GPT :       0.947482 s : 	ENSEMBLE_LABEL =
GPT :       0.947486 s : 	SEQUENCE_NUMBER = 1
GPT :       0.947490 s : 	CREATOR = jinchen
GPT :       0.947494 s : 	CREATOR_HARDWARE = Moonway-x86_64-Linux-6.8.0-60-generic
GPT :       0.947498 s : 	CREATION_DATE = Tue Jun  3 21:16:00 2025 EDT
GPT :       0.947502 s : 	ARCHIVE_DATE = Tue Jun  3 21:16:00 2025 EDT
GPT :       0.947506 s : 	FLOATING_POINT = IEEE64BIG
GPT :       0.947517 s :    END_HEADER
GPT :       0.966869 s : Read 0.00878906 GB at 0.469402 GB/s (0.702305 GB/s for distribution, 1.41605 GB/s for munged read, 145.134 GB/s for checksum, 6.58286 GB/s for munging, 1 readers)
Grid : Message : 0.876963 s :  Stencil object allocated for 4096 sites table 0x7d6c95c44400 GridPtr 0x56a7a196f8c0
Grid : Message : 0.877034 s :  Stencil object allocated for 4096 sites table 0x7d6c95c74400 GridPtr 0x56a7a196f8c0
Grid : Message : 0.877094 s :  Stencil object allocated for 4096 sites table 0x7d6c95ca4400 GridPtr 0x56a7a196f8c0
Grid : Message : 0.877151 s :  Stencil object allocated for 4096 sites table 0x7d6c95cd4400 GridPtr 0x56a7a196f8c0
GPT :       1.023783 s : ====================================================================================================================================
GPT :       1.023805 s :                                                  GPT Memory Report                
GPT :       1.023818 s : ====================================================================================================================================
GPT :       1.023823 s :  Lattice fields on all ranks             0.00878906 GB
GPT :       1.023828 s :  Lattice fields per rank                 0.00878906 GB
GPT :       1.023832 s :  Resident memory per rank                1.64279 GB
GPT :       1.023836 s :  Total memory available (host)           54.6081 GB
GPT :       1.023840 s :  Total memory available (accelerator)    8.48132 GB
GPT :       1.023844 s : ====================================================================================================================================
Grid : Message : 0.960177 s :  Gauge fixing to Coulomb gauge time=3 plaq= 0.595124939 link trace = 0.666276189
Grid : Message : 0.981425 s :  Iteration 0 plaq= 0.595124939 dmuAmu 8.85093533e-09
Grid : Message : 0.981555 s :  Iteration 0 Phi= -4.4473869e-10 Omega= 8.8817842e-16 trG 1
Grid : Message : 0.981560 s : Converged ! 
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.936491e-11, true = 7.936491e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 1.294 secs, Performance = 90.763 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 5.245031e-11, true = 5.245031e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 228.764 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.967815e-11, true = 4.967815e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 231.111 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 6.651921e-11, true = 6.651921e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 227.574 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 5.740163e-11, true = 5.740163e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.916 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 8.672910e-11, true = 8.672910e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 220.476 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.756625e-11, true = 4.756625e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.817 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 6.544039e-11, true = 6.544039e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.865 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 6.529108e-11, true = 6.529108e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 227.252 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.699841e-11, true = 4.699841e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.710 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 2.103506e-11, true = 2.103506e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.843 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.054700e-11, true = 6.054700e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.603 GFLOPS
GPT :       9.539779 s : starting diquark contractions for down quark insertion and Polarization  PpUnpol
GPT :      10.031842 s : diquark contractions for Polarization  0 PpUnpol  done
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 2.172881e-11, true = 2.172881e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.868 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.918920e-11, true = 4.918920e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.353 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.578824e-11, true = 4.578824e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.151 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.920346e-11, true = 5.920346e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.098 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 8.810114e-11, true = 8.810114e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 226.904 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.825230e-11, true = 5.825230e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.470 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 4.126553e-11, true = 4.126553e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 226.135 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.360470e-11, true = 6.360470e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.094 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.191882e-11, true = 5.191882e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.656 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 3.680456e-11, true = 3.680456e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.516 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 7.942729e-11, true = 7.942729e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 227.979 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 8.147231e-11, true = 8.147231e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.516 GFLOPS
GPT :      10.659305 s : starting diquark contractions for up quark insertion and Polarization  PpUnpol
GPT :      11.547504 s : diquark contractions for Polarization  0 PpUnpol  done
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 6.597944e-11, true = 6.597944e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.708 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.345863e-11, true = 5.345863e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 224.059 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.798009e-11, true = 4.798009e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 217.104 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 9.223657e-11, true = 9.223657e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 222.755 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.380898e-11, true = 4.380898e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.363 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.209083e-11, true = 7.209083e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 230.257 GFLOPS
BiCGstab: Convergence at 26 iterations, L2 relative residual: iterated = 1.240542e-11, true = 1.240542e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 236.373 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.706405e-11, true = 6.706405e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 222.462 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.166923e-11, true = 5.166923e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.410 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 8.527514e-11, true = 8.527514e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 222.096 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 3.424021e-11, true = 3.424021e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 233.051 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.483046e-11, true = 7.483046e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 222.853 GFLOPS
GPT :      11.958362 s : TIME PyQUDA: create_bw_seq 0.0007128715515136719
GPT :      11.958384 s : 
                       : contract_PDF loop: GI with links
GPT :      11.999949 s : TIME PyQUDA: contract_PDF 1/3 [0, 0, 0, 0] 0.01055908203125
GPT :      12.135813 s : TIME PyQUDA: create_fw_prop_PDF 1/3 [0, 0, 0, 0] 0.13582587242126465
GPT :      12.135924 s : -->> [[0, 0, 0, 0]]
GPT :      12.139552 s : -->> [[0, 0, 0, 0]]
GPT :      12.152018 s : TIME PyQUDA: contract_PDF 2/3 [0, 1, 0, 0] 0.00951528549194336
GPT :      12.154093 s : TIME PyQUDA: create_fw_prop_PDF 2/3 [0, 1, 0, 0] 0.002053976058959961
GPT :      12.154155 s : -->> [[0, 1, 0, 0]]
GPT :      12.157691 s : -->> [[0, 1, 0, 0]]
GPT :      12.170529 s : TIME PyQUDA: contract_PDF 3/3 [0, 2, 0, 0] 0.00947260856628418
GPT :      12.172604 s : TIME PyQUDA: create_fw_prop_PDF 3/3 [0, 2, 0, 0] 0.0020546913146972656
GPT :      12.172655 s : -->> [[0, 2, 0, 0]]
GPT :      12.176208 s : -->> [[0, 2, 0, 0]]
GPT :      12.179611 s : 
                       : contract_PDF DONE: GI with links
WARNING: Storing profile info disabled

               initQuda Total time =     0.028 secs
                     init     =     0.028 secs ( 99.982%),	 with        2 calls at 1.412e+04 us per call
        total accounted       =     0.028 secs ( 99.982%)
        total missing         =     0.000 secs (  0.018%)

          loadGaugeQuda Total time =     0.141 secs
                 download     =     0.110 secs ( 77.748%),	 with        2 calls at 5.498e+04 us per call
                     init     =     0.000 secs (  0.085%),	 with       13 calls at 9.231e+00 us per call
                  compute     =     0.031 secs ( 22.026%),	 with        4 calls at 7.788e+03 us per call
                    comms     =     0.000 secs (  0.029%),	 with        1 calls at 4.100e+01 us per call
                     free     =     0.000 secs (  0.003%),	 with        3 calls at 1.333e+00 us per call
        total accounted       =     0.141 secs ( 99.890%)
        total missing         =     0.000 secs (  0.110%)

         loadCloverQuda Total time =     6.223 secs
                     init     =     0.000 secs (  0.004%),	 with        6 calls at 4.250e+01 us per call
                  compute     =     5.937 secs ( 95.396%),	 with        7 calls at 8.481e+05 us per call
                    comms     =     0.000 secs (  0.001%),	 with        1 calls at 4.400e+01 us per call
                     free     =     0.000 secs (  0.000%),	 with        3 calls at 2.333e+00 us per call
        total accounted       =     5.937 secs ( 95.401%)
        total missing         =     0.286 secs (  4.599%)

     invertMultiSrcQuda Total time =     1.604 secs
                     init     =     0.076 secs (  4.736%),	 with     1270 calls at 5.980e+01 us per call
                 preamble     =     0.399 secs ( 24.856%),	 with      149 calls at 2.675e+03 us per call
                  compute     =     1.093 secs ( 68.122%),	 with       49 calls at 2.230e+04 us per call
                 epilogue     =     0.001 secs (  0.069%),	 with       72 calls at 1.533e+01 us per call
                     free     =     0.000 secs (  0.007%),	 with      404 calls at 2.847e-01 us per call
        total accounted       =     1.568 secs ( 97.789%)
        total missing         =     0.035 secs (  2.211%)

                endQuda Total time =     0.004 secs
                     free     =     0.000 secs (  0.081%),	 with        7 calls at 4.286e-01 us per call
        total accounted       =     0.000 secs (  0.081%)
        total missing         =     0.004 secs ( 99.919%)

       initQuda-endQuda Total time =    11.265 secs

                   QUDA Total time =     8.000 secs
                 download     =     0.110 secs (  1.374%),	 with        2 calls at 5.498e+04 us per call
                     init     =     0.105 secs (  1.307%),	 with     1291 calls at 8.101e+01 us per call
                 preamble     =     0.399 secs (  4.983%),	 with      149 calls at 2.675e+03 us per call
                  compute     =     7.060 secs ( 88.251%),	 with       60 calls at 1.177e+05 us per call
                    comms     =     0.000 secs (  0.001%),	 with        2 calls at 4.300e+01 us per call
                 epilogue     =     0.001 secs (  0.014%),	 with       72 calls at 1.536e+01 us per call
                     free     =     0.000 secs (  0.002%),	 with      417 calls at 3.118e-01 us per call
        total accounted       =     7.675 secs ( 95.932%)
        total missing         =     0.325 secs (  4.068%)

Device memory used = 53.1 MiB
Pinned device memory used = 0.0 MiB
Managed memory used = 0.0 MiB
Shmem memory used = 0.0 MiB
Page-locked host memory used = 2.5 MiB
Total host memory used >= 16.5 MiB

