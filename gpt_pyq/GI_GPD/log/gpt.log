MPI version is unknown - bad things may happen
AcceleratorCudaInit[0]: ========================
AcceleratorCudaInit[0]: Device Number    : 0
AcceleratorCudaInit[0]: ========================
AcceleratorCudaInit[0]: Device identifier: NVIDIA GeForce RTX 3060
AcceleratorCudaInit[0]:   totalGlobalMem: 12626493440 
AcceleratorCudaInit[0]:   managedMemory: 1 
AcceleratorCudaInit[0]:   isMultiGpuBoard: 0 
AcceleratorCudaInit[0]:   warpSize: 32 
AcceleratorCudaInit[0]:   pciBusID: 7 
AcceleratorCudaInit[0]:   pciDeviceID: 0 
AcceleratorCudaInit[0]: maxGridSize (2147483647,65535,65535)
AcceleratorCudaInit: using default device 
AcceleratorCudaInit: assume user either uses
AcceleratorCudaInit: a) IBM jsrun, or 
AcceleratorCudaInit: b) invokes through a wrapping script to set CUDA_VISIBLE_DEVICES, UCX_NET_DEVICES, and numa binding 
AcceleratorCudaInit: Configure options --enable-setdevice=no 
local rank 0 device 0 bus id: 0000:07:00.0
AcceleratorCudaInit: ================================================
SharedMemoryMpi:  World communicator of size 1
SharedMemoryMpi:  Node  communicator of size 1
0SharedMemoryMpi:  SharedMemoryMPI.cc acceleratorAllocDevice 1073741824bytes at 0x7bf290000000 - 7bf2cfffffff for comms buffers 
Setting up IPC

__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
__|_ |  |  |  |  |  |  |  |  |  |  |  | _|__
__|_                                    _|__
__|_   GGGG    RRRR    III    DDDD      _|__
__|_  G        R   R    I     D   D     _|__
__|_  G        R   R    I     D    D    _|__
__|_  G  GG    RRRR     I     D    D    _|__
__|_  G   G    R  R     I     D   D     _|__
__|_   GGGG    R   R   III    DDDD      _|__
__|_                                    _|__
__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
__|__|__|__|__|__|__|__|__|__|__|__|__|__|__
  |  |  |  |  |  |  |  |  |  |  |  |  |  |  


Copyright (C) 2015 Peter Boyle, Azusa Yamaguchi, Guido Cossu, Antonin Portelli and other authors

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
Current Grid git commit hash=46c717e873bb91677e8961a6fc5bfc58bc2171a5: (HEAD -> gpt_proton, origin/gpt_proton) clean

Grid : Message : ================================================ 
Grid : Message : MPI is initialised and logging filters activated 
Grid : Message : ================================================ 
Grid : Message : This rank is running on host Moonway
Grid : Message : Requested 1073741824 byte stencil comms buffers 
Grid : Message : MemoryManager Cache 10101194752 bytes 
Grid : Message : MemoryManager::Init() setting up
Grid : Message : MemoryManager::Init() cache pool for recent host   allocations: SMALL 8 LARGE 2 HUGE 0
Grid : Message : MemoryManager::Init() cache pool for recent device allocations: SMALL 16 LARGE 8 Huge 0
Grid : Message : MemoryManager::Init() cache pool for recent shared allocations: SMALL 16 LARGE 8 Huge 0
Grid : Message : MemoryManager::Init() Non unified: Caching accelerator data in dedicated memory
Grid : Message : MemoryManager::Init() Using cudaMalloc

=============================================
              Initialized GPT                
     Copyright (C) 2020 Christoph Lehner     
=============================================
GPT :       0.903922 s : --lat_tag l64c64a076
GPT :       0.903955 s : --sm_tag 1HYP_GSRC_W90_k3_T5
GPT :       0.903964 s : --config_num 0
PyQUDA INFO: Using the grid size (1, 1, 1, 1)
PyQUDA INFO: Using CUDA backend cupy
PyQUDA INFO: Using QUDA_RESOURCE_PATH=.cache
Disabling GPU-Direct RDMA access
Enabling peer-to-peer copy engine and direct load/store access
QUDA 1.1.0 (git 1.1.0-e23cd7e4f-sm_86)
CUDA Driver version = 12020
CUDA Runtime version = 12020
Graphic driver version = 535.261.03
Found device 0: NVIDIA GeForce RTX 3060
Using device 0: NVIDIA GeForce RTX 3060
Initializing monitoring on device 0: NVIDIA GeForce RTX 3060
WARNING: Data reordering done on GPU (set with QUDA_REORDER_LOCATION=GPU/CPU)
WARNING: The path ".cache" specified by QUDA_RESOURCE_PATH does not exist or is not a directory.
WARNING: Caching of tuned parameters will be disabled
WARNING: Cache file not found.  All kernels will be re-tuned (if tuning is enabled).
WARNING: Using device memory pool allocator
WARNING: Using pinned memory pool allocator
cublasCreated successfully
GPT :       0.934745 s : NERSC file format; reading ../../conf/S8T32_cg/gauge/wilson_b6.cg.1e-08.0
GPT :       0.934762 s :    BEGIN_HEADER
GPT :       0.934772 s : 	HDR_VERSION = 1.0
GPT :       0.934779 s : 	DATATYPE = 4D_SU3_GAUGE_3x3
GPT :       0.934785 s : 	STORAGE_FORMAT =
GPT :       0.934792 s : 	DIMENSION_1 = 8
GPT :       0.934798 s : 	DIMENSION_2 = 8
GPT :       0.934804 s : 	DIMENSION_3 = 8
GPT :       0.934810 s : 	DIMENSION_4 = 32
GPT :       0.934816 s : 	LINK_TRACE = 0.6662761893
GPT :       0.934821 s : 	PLAQUETTE  = 0.595124939
GPT :       0.934826 s : 	BOUNDARY_1 = PERIODIC
GPT :       0.934831 s : 	BOUNDARY_2 = PERIODIC
GPT :       0.934838 s : 	BOUNDARY_3 = PERIODIC
GPT :       0.934843 s : 	BOUNDARY_4 = PERIODIC
GPT :       0.934849 s : 	CHECKSUM =   d62a45d9
GPT :       0.934854 s : 	SCIDAC_CHECKSUMA =          0
GPT :       0.934859 s : 	SCIDAC_CHECKSUMB =          0
GPT :       0.934865 s : 	ENSEMBLE_ID = gpt
GPT :       0.934870 s : 	ENSEMBLE_LABEL =
GPT :       0.934876 s : 	SEQUENCE_NUMBER = 1
GPT :       0.934881 s : 	CREATOR = jinchen
GPT :       0.934887 s : 	CREATOR_HARDWARE = Moonway-x86_64-Linux-6.8.0-60-generic
GPT :       0.934892 s : 	CREATION_DATE = Tue Jun  3 21:16:00 2025 EDT
GPT :       0.934899 s : 	ARCHIVE_DATE = Tue Jun  3 21:16:00 2025 EDT
GPT :       0.934905 s : 	FLOATING_POINT = IEEE64BIG
GPT :       0.934910 s :    END_HEADER
GPT :       0.954029 s : Read 0.00878906 GB at 0.475947 GB/s (0.718905 GB/s for distribution, 1.40901 GB/s for munged read, 144.565 GB/s for checksum, 6.41783 GB/s for munging, 1 readers)
Grid : Message : 0.867987 s :  Stencil object allocated for 4096 sites table 0x7bf317c44400 GridPtr 0x619260fde390
Grid : Message : 0.868059 s :  Stencil object allocated for 4096 sites table 0x7bf317c74400 GridPtr 0x619260fde390
Grid : Message : 0.868118 s :  Stencil object allocated for 4096 sites table 0x7bf317ca4400 GridPtr 0x619260fde390
Grid : Message : 0.868175 s :  Stencil object allocated for 4096 sites table 0x7bf317cd4400 GridPtr 0x619260fde390
GPT :       1.039815 s : ====================================================================================================================================
GPT :       1.039842 s :                                                  GPT Memory Report                
GPT :       1.039858 s : ====================================================================================================================================
GPT :       1.039867 s :  Lattice fields on all ranks             0.00878906 GB
GPT :       1.039873 s :  Lattice fields per rank                 0.00878906 GB
GPT :       1.039878 s :  Resident memory per rank                1.65115 GB
GPT :       1.039884 s :  Total memory available (host)           54.6424 GB
GPT :       1.039890 s :  Total memory available (accelerator)    8.46179 GB
GPT :       1.039895 s : ====================================================================================================================================
Grid : Message : 0.980584 s :  Gauge fixing to Coulomb gauge time=3 plaq= 0.595124939 link trace = 0.666276189
Grid : Message : 1.188000 s :  Iteration 0 plaq= 0.595124939 dmuAmu 8.85093533e-09
Grid : Message : 1.201000 s :  Iteration 0 Phi= -4.4473869e-10 Omega= 8.8817842e-16 trG 1
Grid : Message : 1.201600 s : Converged ! 
GPT :       1.110477 s : DEBUG plaquette U_prime: 0.5951249390283283
GPT :       5.722899 s : DEBUG plaquette gauge: [0.5951249390283283, 0.594569877214337, 0.5956800008423196]
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.762426e-11, true = 7.762426e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 1.302 secs, Performance = 89.915 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 5.197028e-11, true = 5.197028e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 227.252 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.968345e-11, true = 4.968345e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.965 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 6.655712e-11, true = 6.655712e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 226.210 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 5.672247e-11, true = 5.672247e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.117 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 8.654806e-11, true = 8.654806e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 218.531 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.798975e-11, true = 4.798975e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.989 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 6.490192e-11, true = 6.490192e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.918 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 6.514492e-11, true = 6.514492e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.008 secs, Performance = 226.850 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.582815e-11, true = 4.582815e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.752 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 2.128913e-11, true = 2.128913e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.278 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.017424e-11, true = 6.017424e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.464 GFLOPS
GPT :      14.820141 s : starting diquark contractions for down quark insertion and Polarization  PpUnpol
GPT :      15.252067 s : diquark contractions for Polarization  0 PpUnpol  done
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 1.750381e-11, true = 1.750381e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.640 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.616692e-11, true = 4.616692e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.787 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.502879e-11, true = 4.502879e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.726 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 2.104223e-11, true = 2.104223e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 224.539 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 8.741592e-11, true = 8.741592e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 226.024 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.114042e-11, true = 6.114042e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.647 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 3.832957e-11, true = 3.832957e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 231.769 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.461881e-11, true = 6.461881e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.569 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.195605e-11, true = 5.195605e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.910 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.128545e-11, true = 4.128545e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.514 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 7.759212e-11, true = 7.759212e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.733 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 8.281221e-11, true = 8.281221e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.621 GFLOPS
GPT :      15.814878 s : starting diquark contractions for up quark insertion and Polarization  PpUnpol
GPT :      15.953254 s : diquark contractions for Polarization  0 PpUnpol  done
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 7.111604e-11, true = 7.111604e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.010 secs, Performance = 207.281 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.368537e-11, true = 5.368537e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 222.462 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.872897e-11, true = 4.872897e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.152 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 2.290333e-11, true = 2.290333e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 224.851 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.134572e-11, true = 4.134572e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.647 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.562907e-11, true = 7.562907e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.517 GFLOPS
BiCGstab: Convergence at 26 iterations, L2 relative residual: iterated = 1.347722e-11, true = 1.347722e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 233.992 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.630517e-11, true = 6.630517e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.393 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.143917e-11, true = 5.143917e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.647 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.628635e-11, true = 7.628635e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.514 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.182716e-11, true = 6.182716e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.386 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 8.471469e-11, true = 8.471469e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.538 GFLOPS
GPT :      16.530046 s : starting diquark contractions for down quark insertion and Polarization  PpUnpol
GPT :      16.659037 s : diquark contractions for Polarization  0 PpUnpol  done
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 1.750381e-11, true = 1.750381e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.733 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.616692e-11, true = 4.616692e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.565 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.502879e-11, true = 4.502879e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.436 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 2.104223e-11, true = 2.104223e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 224.755 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 8.741592e-11, true = 8.741592e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.521 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.114042e-11, true = 6.114042e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.700 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 3.832957e-11, true = 3.832957e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 231.769 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.461881e-11, true = 6.461881e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 227.682 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.195605e-11, true = 5.195605e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.805 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.128545e-11, true = 4.128545e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.417 GFLOPS
BiCGstab: Convergence at 23 iterations, L2 relative residual: iterated = 7.759212e-11, true = 7.759212e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 225.231 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 8.281221e-11, true = 8.281221e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.595 GFLOPS
GPT :      17.273994 s : starting diquark contractions for up quark insertion and Polarization  PpUnpol
GPT :      17.420799 s : diquark contractions for Polarization  0 PpUnpol  done
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 7.111604e-11, true = 7.111604e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.010 secs, Performance = 207.656 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.368537e-11, true = 5.368537e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 223.910 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.872897e-11, true = 4.872897e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.926 GFLOPS
BiCGstab: Convergence at 25 iterations, L2 relative residual: iterated = 2.290333e-11, true = 2.290333e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 224.611 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 4.134572e-11, true = 4.134572e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.252 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.562907e-11, true = 7.562907e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 229.225 GFLOPS
BiCGstab: Convergence at 26 iterations, L2 relative residual: iterated = 1.347722e-11, true = 1.347722e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 234.479 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.630517e-11, true = 6.630517e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.538 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 5.143917e-11, true = 5.143917e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.543 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 7.628635e-11, true = 7.628635e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 221.224 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 6.182716e-11, true = 6.182716e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 228.936 GFLOPS
BiCGstab: Convergence at 24 iterations, L2 relative residual: iterated = 8.471469e-11, true = 8.471469e-11 (requested = 1.000000e-10)
PyQUDA INFO: Time = 0.009 secs, Performance = 222.267 GFLOPS
GPT :      17.866276 s : TIME GPT: create_bw_seq 0.04690289497375488
GPT :      17.866311 s : 
                       : contract_PDF loop: GI with links
GPT :      17.875744 s : Creating list of W*prop_f
GPT :      17.879762 s : TIME GPT: create_fw_prop_PDF 1/3 [0, 0, 0, 0] 0.013419389724731445
GPT :      17.879790 s : Starting TMD contractions
GPT :      17.900470 s : -->> [[0, 0, 0, 0]]
GPT :      17.922021 s : -->> [[0, 0, 0, 0]]
GPT :      17.925637 s : TIME GPT: contract_PDF 1/3 [0, 0, 0, 0] 0.059294939041137695
GPT :      17.929464 s : Creating list of W*prop_f
GPT :      17.933185 s : TIME GPT: create_fw_prop_PDF 2/3 [0, 1, 0, 0] 0.007528781890869141
GPT :      17.933206 s : Starting TMD contractions
GPT :      17.946589 s : -->> [[0, 1, 0, 0]]
GPT :      17.964124 s : -->> [[0, 1, 0, 0]]
GPT :      17.968307 s : TIME GPT: contract_PDF 2/3 [0, 1, 0, 0] 0.04265022277832031
GPT :      17.971468 s : Creating list of W*prop_f
GPT :      17.975223 s : TIME GPT: create_fw_prop_PDF 3/3 [0, 2, 0, 0] 0.0068967342376708984
GPT :      17.975240 s : Starting TMD contractions
GPT :      17.988533 s : -->> [[0, 2, 0, 0]]
GPT :      18.005995 s : -->> [[0, 2, 0, 0]]
GPT :      18.010161 s : TIME GPT: contract_PDF 3/3 [0, 2, 0, 0] 0.04183530807495117
GPT :      18.010173 s : 
                       : contract_PDF DONE: GI with links
WARNING: Storing profile info disabled

               initQuda Total time =     0.029 secs
                     init     =     0.029 secs ( 99.983%),	 with        2 calls at 1.443e+04 us per call
        total accounted       =     0.029 secs ( 99.983%)
        total missing         =     0.000 secs (  0.017%)

          loadGaugeQuda Total time =     0.221 secs
                 download     =     0.173 secs ( 78.333%),	 with        3 calls at 5.777e+04 us per call
                     init     =     0.000 secs (  0.052%),	 with       19 calls at 6.053e+00 us per call
                  compute     =     0.030 secs ( 13.661%),	 with        5 calls at 6.046e+03 us per call
                    comms     =     0.000 secs (  0.038%),	 with        2 calls at 4.250e+01 us per call
                     free     =     0.000 secs (  0.001%),	 with        4 calls at 7.500e-01 us per call
        total accounted       =     0.204 secs ( 92.086%)
        total missing         =     0.018 secs (  7.914%)

         loadCloverQuda Total time =     6.200 secs
                     init     =     0.000 secs (  0.004%),	 with        5 calls at 4.840e+01 us per call
                  compute     =     5.979 secs ( 96.446%),	 with        7 calls at 8.542e+05 us per call
                     free     =     0.000 secs (  0.000%),	 with        3 calls at 2.333e+00 us per call
        total accounted       =     5.980 secs ( 96.450%)
        total missing         =     0.220 secs (  3.550%)

     invertMultiSrcQuda Total time =     1.828 secs
                     init     =     0.085 secs (  4.624%),	 with     2110 calls at 4.006e+01 us per call
                 preamble     =     0.409 secs ( 22.360%),	 with      245 calls at 1.668e+03 us per call
                  compute     =     1.297 secs ( 70.942%),	 with       73 calls at 1.776e+04 us per call
                 epilogue     =     0.002 secs (  0.100%),	 with      120 calls at 1.525e+01 us per call
                     free     =     0.000 secs (  0.009%),	 with      668 calls at 2.485e-01 us per call
        total accounted       =     1.792 secs ( 98.036%)
        total missing         =     0.036 secs (  1.964%)

   gaugeObservablesQuda Total time =     4.497 secs
                     init     =     0.000 secs (  0.002%),	 with        1 calls at 8.700e+01 us per call
                  compute     =     4.427 secs ( 98.439%),	 with        1 calls at 4.427e+06 us per call
                    comms     =     0.000 secs (  0.001%),	 with        1 calls at 6.100e+01 us per call
        total accounted       =     4.427 secs ( 98.442%)
        total missing         =     0.070 secs (  1.558%)

                endQuda Total time =     0.004 secs
                     free     =     0.000 secs (  0.131%),	 with        7 calls at 7.143e-01 us per call
        total accounted       =     0.000 secs (  0.131%)
        total missing         =     0.004 secs ( 99.869%)

       initQuda-endQuda Total time =    17.109 secs

                   QUDA Total time =    12.779 secs
                 download     =     0.173 secs (  1.356%),	 with        3 calls at 5.777e+04 us per call
                     init     =     0.114 secs (  0.891%),	 with     2137 calls at 5.328e+01 us per call
                 preamble     =     0.409 secs (  3.199%),	 with      245 calls at 1.668e+03 us per call
                  compute     =    11.733 secs ( 91.819%),	 with       86 calls at 1.364e+05 us per call
                    comms     =     0.000 secs (  0.001%),	 with        3 calls at 4.867e+01 us per call
                 epilogue     =     0.002 secs (  0.014%),	 with      120 calls at 1.523e+01 us per call
                     free     =     0.000 secs (  0.001%),	 with      682 calls at 2.595e-01 us per call
        total accounted       =    12.432 secs ( 97.282%)
        total missing         =     0.347 secs (  2.718%)

Device memory used = 60.7 MiB
Pinned device memory used = 0.0 MiB
Managed memory used = 0.0 MiB
Shmem memory used = 0.0 MiB
Page-locked host memory used = 3.7 MiB
Total host memory used >= 17.7 MiB

